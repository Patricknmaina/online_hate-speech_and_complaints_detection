{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6Bw2r1q4pu5",
        "outputId": "d466d192-10b6-4589-9ee8-ffbeb9bad017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount google drive to access files and save outputs persistently within Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi3w4I1e5IND",
        "outputId": "e4785acc-bc88-49c0-e5d8-01425d90b306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Aug  4 20:42:23 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0             49W /  400W |    5879MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# check for GPU availability\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "vpyXQeXNznsC"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "# Filter out the specific FutureWarning related to encoder_attention_mask\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    message=\"`encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\",\n",
        "    category=FutureWarning\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J4VTxwai98JL"
      },
      "outputs": [],
      "source": [
        "# install wandb\n",
        "!pip install wandb --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3xZdVmA09sDV"
      },
      "outputs": [],
      "source": [
        "# Disable Weights & Biases (wandb) to allow training without requiring an API key or logging\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "fljy1GBO5LzC"
      },
      "outputs": [],
      "source": [
        "# load the preprocessed train, validation and test datasets\n",
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/Safaricom-processed-dataset/train_processed.csv')\n",
        "val_df = pd.read_csv('/content/drive/MyDrive/Safaricom-processed-dataset/val_processed.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Safaricom-processed-dataset/test_processed.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "M-xFOawHrsQN",
        "outputId": "f747e47b-3127-41ee-ecbc-7046fb39004d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 3011,\n  \"fields\": [\n    {\n      \"column\": \"Content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2975,\n        \"samples\": [\n          \".@Safaricom, I got 20 bob credit, tried buying bundles, but you said insufficient balance. Checked, it was 19.095. After texting you, it's now 17.22. No subscriptions. What's going on? This is new line, now I can't buy 1hr bundle!!\",\n          \"@dotty_family @safaricom @AIRTEL_KE @odibets @IPOA_KE Tunasikitika kuwa unahisi hivi.\\n\\nTafadhali fafanua swala lako kwa usaidizi zaidi.\\n\\nAsante.\\n^WL\",\n          \"50M Connected isn\\u2019t just a stat. It\\u2019s a symbol of how @Safaricom has scaled digital inclusion and access to opportunity across Kenya  from cities to villages, from youth to elders. Customer Growth. https://t.co/1OyaM4Ci5P\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Likes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46,\n        \"min\": 0,\n        \"max\": 2528,\n        \"num_unique_values\": 44,\n        \"samples\": [\n          116,\n          30,\n          37\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Retweets\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23,\n        \"min\": 0,\n        \"max\": 1244,\n        \"num_unique_values\": 28,\n        \"samples\": [\n          10,\n          63,\n          29\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Replies\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 122,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0,\n          1,\n          24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quotes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 40,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          18,\n          1,\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Views\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1385,\n        \"min\": 0,\n        \"max\": 64438,\n        \"num_unique_values\": 340,\n        \"samples\": [\n          205,\n          67,\n          71\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Labels\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Neutral\",\n          \"Data protection and privacy concern\",\n          \"Hate Speech\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2961,\n        \"samples\": [\n          \"Tutoeric safaricom You have to go to saf\",\n          \"MPesa Safaricoms mobile money vertical continues to dominate Kenyas mobile money market According to the Communications Authority of Kenya the company accounts for 988 of the 291 million registered mobile money subscriptions in the country\",\n          \"MartinKN safaricom zuku faiba HAve you seen some of the speeds guys are getting and some of which even cheeper than what I am paying for my 30MBps\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"encoded_labels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          6,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "train_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1c157840-67e4-4575-8ff1-168f99690bc6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Content</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Replies</th>\n",
              "      <th>Quotes</th>\n",
              "      <th>Views</th>\n",
              "      <th>Labels</th>\n",
              "      <th>cleaned_sentence</th>\n",
              "      <th>encoded_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@ledamalekina @safaricom Exactly</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>ledamalekina safaricom Exactly</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@InteriorKE And why are FanakaLotto still oper...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Data protection and privacy concern</td>\n",
              "      <td>InteriorKE And why are FanakaLotto still opera...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@safaricom rudisheni hii na mnipee bundles .sa...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>Internet or airtime bundle complaint</td>\n",
              "      <td>safaricom rudisheni hii na mnipee bundles sasa...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@RobertAlai @safaricom @PeterNdegwa_ Hii manen...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>RobertAlai safaricom PeterNdegwa Hii maneno pe...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@evenmaina @safaricom PLC I hate you , mlikwam...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>Customer care complaint</td>\n",
              "      <td>evenmaina safaricom PLC I hate you mlikwamilia...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c157840-67e4-4575-8ff1-168f99690bc6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c157840-67e4-4575-8ff1-168f99690bc6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c157840-67e4-4575-8ff1-168f99690bc6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6d72065d-b850-45aa-a7e2-18c351956373\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d72065d-b850-45aa-a7e2-18c351956373')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6d72065d-b850-45aa-a7e2-18c351956373 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                             Content  Likes  Retweets  \\\n",
              "0                   @ledamalekina @safaricom Exactly      1         0   \n",
              "1  @InteriorKE And why are FanakaLotto still oper...      0         0   \n",
              "2  @safaricom rudisheni hii na mnipee bundles .sa...      1         0   \n",
              "3  @RobertAlai @safaricom @PeterNdegwa_ Hii manen...      0         0   \n",
              "4  @evenmaina @safaricom PLC I hate you , mlikwam...      0         0   \n",
              "\n",
              "   Replies  Quotes  Views                                Labels  \\\n",
              "0        0       0      0                               Neutral   \n",
              "1        0       0      0   Data protection and privacy concern   \n",
              "2        0       0     16  Internet or airtime bundle complaint   \n",
              "3        0       0     48                               Neutral   \n",
              "4        0       0     16               Customer care complaint   \n",
              "\n",
              "                                    cleaned_sentence  encoded_labels  \n",
              "0                     ledamalekina safaricom Exactly               6  \n",
              "1  InteriorKE And why are FanakaLotto still opera...               1  \n",
              "2  safaricom rudisheni hii na mnipee bundles sasa...               3  \n",
              "3  RobertAlai safaricom PeterNdegwa Hii maneno pe...               6  \n",
              "4  evenmaina safaricom PLC I hate you mlikwamilia...               0  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# view the first 5 rows in train dataset\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL__QA1lEsQ6",
        "outputId": "2f765135-1458-4dce-d126-7272f6c10da6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution in training data:\n",
            "encoded_labels\n",
            "0     327\n",
            "1     155\n",
            "2     238\n",
            "3     260\n",
            "4     215\n",
            "5     218\n",
            "6    1598\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check the distribution of the target variable in the training data\n",
        "label_counts = train_df['encoded_labels'].value_counts().sort_index()\n",
        "print(\"Class distribution in training data:\")\n",
        "print(label_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "CKLqZ25U5pjM"
      },
      "outputs": [],
      "source": [
        "# initialize the pre-trained XLM-RoBERTa tokenizer\n",
        "from transformers import BertTokenizer, XLMRobertaTokenizer, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-large')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "FDnZM84F53jP"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Tokenizes a list of texts using the pre-defined tokenizer.\n",
        "\n",
        "Args:\n",
        "    texts (list or pd.Series): List or Series of sentences to tokenize.\n",
        "    max_length (int): Maximum sequence length after padding/truncation.\n",
        "\n",
        "    Returns:\n",
        "    dict: Dictionary of tokenized outputs as PyTorch tensors.\n",
        "'''\n",
        "def tokenize_texts(texts, max_length=256):\n",
        "    return tokenizer(\n",
        "        list(texts),\n",
        "        padding='max_length', # pad shorter texts to max_length\n",
        "        truncation=True, # truncate longer texts\n",
        "        max_length=max_length,\n",
        "        return_tensors='pt' # return PyTorch tensors\n",
        "    )\n",
        "# Tokenize the cleaned sentences from each dataset split for model input\n",
        "train_tokens = tokenize_texts(train_df['cleaned_sentence'].tolist())\n",
        "val_tokens = tokenize_texts(val_df['cleaned_sentence'].tolist())\n",
        "test_tokens = tokenize_texts(test_df['cleaned_sentence'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "OQpEJ-cr6Ave"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Convert label columns from each dataset split into PyTorch tensors\n",
        "For compatibility with model training and loss calculation\n",
        "'''\n",
        "import torch\n",
        "\n",
        "train_labels = torch.tensor(train_df['encoded_labels'].values)\n",
        "val_labels = torch.tensor(val_df['encoded_labels'].values)\n",
        "test_labels = torch.tensor(test_df['encoded_labels'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "3zFrFLa26NYH"
      },
      "outputs": [],
      "source": [
        "# define the custom Pytorch Dataset\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TweetDataset(Dataset):\n",
        "  \"\"\"\n",
        "  A custom Pytorch dataset for handling tokenized inputs and labels for tweet classification\n",
        "  It allows easy batching and data loading during training and evaluation\n",
        "  \"\"\"\n",
        "  def __init__(self, tokens, labels):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        tokens (list): Tokenized inputs like input_ids and attention mask (Pytorch tensors).\n",
        "        labels (torch.Tensor): Corresponding labels tensor\n",
        "    \"\"\"\n",
        "    self.tokens = tokens\n",
        "    self.labels = labels\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    \"\"\"\n",
        "    Retrieve a single sample by index\n",
        "\n",
        "    Returns:\n",
        "        dict: Toknized inputs and corresponding labels\n",
        "    \"\"\"\n",
        "    item = {key: val[idx] for key, val in self.tokens.items()}\n",
        "    item['labels'] = self.labels[idx]\n",
        "    return item\n",
        "\n",
        "  def __len__(self):\n",
        "    # returns the total number of samples\n",
        "    return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "UVZl0-gGw5o4"
      },
      "outputs": [],
      "source": [
        "# create the dataset objects for train, validation and test sets\n",
        "train_dataset = TweetDataset(train_tokens, train_labels)\n",
        "val_dataset = TweetDataset(val_tokens, val_labels)\n",
        "test_dataset = TweetDataset(test_tokens, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYJAnni66f0A"
      },
      "source": [
        "## Model Training and Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcgs_dl96iy1",
        "outputId": "30ccefca-b748-4091-89f1-e3febf075589"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, XLMRobertaForSequenceClassification, AutoModelForSequenceClassification\n",
        "\n",
        "# load the pre-trained XLM-RoBERTa model with a classification head for 7 classes\n",
        "model = AutoModelForSequenceClassification.from_pretrained('xlm-roberta-large', num_labels=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "U8mxSsOh6456"
      },
      "outputs": [],
      "source": [
        "# # Set up the optimizer and learning rate scheduler for training\n",
        "\n",
        "# from torch.optim import AdamW\n",
        "# from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# batch_size = 16\n",
        "# num_epochs = 3\n",
        "\n",
        "# # AdamW optimizer is commonly used with transformer models for weight decay regularization\n",
        "# optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# # Calculate total number of training steps (batches * epochs)\n",
        "# num_training_steps = len(train_dataset) // batch_size * num_epochs\n",
        "\n",
        "# # Linear learning rate scheduler with optional warmup steps (none here)\n",
        "# # Gradually decreases the learning rate from the initial value to zero over training\n",
        "# lr_scheduler = get_linear_schedule_with_warmup(\n",
        "#     optimizer,\n",
        "#     num_warmup_steps=0,\n",
        "#     num_training_steps=num_training_steps\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7SqDWSO7RDV",
        "outputId": "7a622762-06ad-4ba2-c2cf-a6c6caca9c60"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ],
      "source": [
        "# define the training configurations and hyperparameters for the trainer API\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/results/',     # output directory\n",
        "    num_train_epochs=5,                 # number of training epochs\n",
        "    per_device_train_batch_size=16,     # training batch size per device\n",
        "    per_device_eval_batch_size=16,      # evaluation batch size\n",
        "    eval_strategy='epoch',              # evaluate at the end of each epoch\n",
        "    save_strategy='epoch',              # save checkpoint every epoch\n",
        "    learning_rate=2e-5,                 # learning rate\n",
        "    weight_decay=0.01,                  # weight decay for regularization\n",
        "    logging_dir=None,                   # logging directory\n",
        "    logging_steps=50,                   # log every 50 steps\n",
        "    load_best_model_at_end=False,       # load the best model at the end of training\n",
        "    metric_for_best_model='f1',         # metric to monitor for best model\n",
        "    greater_is_better=True              # higher metric values are better\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "7031H8-t7vOj"
      },
      "outputs": [],
      "source": [
        "# define the metric computation function\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"\n",
        "    Compute accuracy, precision, recall, and F1-score for model evaluation.\n",
        "\n",
        "    Args:\n",
        "        eval_pred (tuple): Tuple containing logits (model outputs) and true labels.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with 'accuracy', 'f1', 'precision', and 'recall' scores.\n",
        "    \"\"\"\n",
        "\n",
        "    logits, labels = eval_pred\n",
        "    # Convert logits to predicted class indices\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Calculate precision, recall, f1-score with weighted average (handles class imbalance)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
        "\n",
        "    # Calculate overall accuracy\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "\n",
        "    # Return all metrics in a dictionary format expected by Trainer\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "4N6FbGW09Nii",
        "outputId": "cb193cb7-c233-4011-8c79-ea04d02a21d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3117783210.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='945' max='945' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [945/945 10:44, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.280600</td>\n",
              "      <td>0.962490</td>\n",
              "      <td>0.674671</td>\n",
              "      <td>0.642883</td>\n",
              "      <td>0.660637</td>\n",
              "      <td>0.674671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.869100</td>\n",
              "      <td>0.742392</td>\n",
              "      <td>0.749032</td>\n",
              "      <td>0.734229</td>\n",
              "      <td>0.737821</td>\n",
              "      <td>0.749032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.591600</td>\n",
              "      <td>0.705653</td>\n",
              "      <td>0.779241</td>\n",
              "      <td>0.771078</td>\n",
              "      <td>0.773241</td>\n",
              "      <td>0.779241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.431700</td>\n",
              "      <td>0.693250</td>\n",
              "      <td>0.775368</td>\n",
              "      <td>0.774539</td>\n",
              "      <td>0.776855</td>\n",
              "      <td>0.775368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.288600</td>\n",
              "      <td>0.730946</td>\n",
              "      <td>0.772270</td>\n",
              "      <td>0.771129</td>\n",
              "      <td>0.773421</td>\n",
              "      <td>0.772270</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=945, training_loss=0.7231592168252935, metrics={'train_runtime': 644.9981, 'train_samples_per_second': 23.341, 'train_steps_per_second': 1.465, 'total_flos': 7015231850411520.0, 'train_loss': 0.7231592168252935, 'epoch': 5.0})"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "# initialize the Hugging Face trainer with model, datasets, tokenizer, and evaluation metrics\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# initialize the training process\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bqla38OEMl2F",
        "outputId": "1393fcce-0ac2-4eae-effe-f04a6bcb702a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('model/tokenizer_config.json',\n",
              " 'model/special_tokens_map.json',\n",
              " 'model/sentencepiece.bpe.model',\n",
              " 'model/added_tokens.json',\n",
              " 'model/tokenizer.json')"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the fine-tuned model and tokenizer to the specified directory\n",
        "# This allows loading the trained model/tokenizer later for inference or further training\n",
        "model.save_pretrained('model/')\n",
        "tokenizer.save_pretrained('model/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "YkQNAtjT57PQ",
        "outputId": "c05f5453-09f6-476c-e2c4-91875c8218c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='232' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [116/116 01:25]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.7143315076828003, 'eval_accuracy': 0.7885032537960954, 'eval_f1': 0.7866287463898118, 'eval_precision': 0.7876804781308033, 'eval_recall': 0.7885032537960954, 'eval_runtime': 18.8787, 'eval_samples_per_second': 97.676, 'eval_steps_per_second': 6.144, 'epoch': 5.0}\n"
          ]
        }
      ],
      "source": [
        "# evaluate on the test dataset\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Get predictions from the trainer\n",
        "results = trainer.evaluate(test_dataset)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "ZZIKSFng3uJL",
        "outputId": "b88da3d1-ce73-4bcd-9fbf-af64141a2e7f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.55      0.59       201\n",
            "           1       0.72      0.60      0.66        95\n",
            "           2       0.61      0.66      0.63       146\n",
            "           3       0.74      0.84      0.79       159\n",
            "           4       0.70      0.80      0.75       132\n",
            "           5       0.74      0.68      0.71       133\n",
            "           6       0.88      0.88      0.88       978\n",
            "\n",
            "    accuracy                           0.79      1844\n",
            "   macro avg       0.72      0.72      0.71      1844\n",
            "weighted avg       0.79      0.79      0.79      1844\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Extract logits and labels\n",
        "predictions = trainer.predict(test_dataset)\n",
        "logits = predictions.predictions\n",
        "labels = predictions.label_ids\n",
        "\n",
        "# Convert logits to predicted class indices\n",
        "predicted_labels = np.argmax(logits, axis=-1)\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(labels, predicted_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62ofXkRVswsC"
      },
      "source": [
        "## mBERT Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "gLgv3Hbp6SW_"
      },
      "outputs": [],
      "source": [
        "# define the mBERT tokenizer\n",
        "from transformers import BertTokenizer, AutoTokenizer\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "hTUI6ISts_iQ"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Tokenizes a list of texts using the pre-defined tokenizer.\n",
        "\n",
        "Args:\n",
        "    texts (list or pd.Series): List or Series of sentences to tokenize.\n",
        "    max_length (int): Maximum sequence length after padding/truncation.\n",
        "\n",
        "    Returns:\n",
        "    dict: Dictionary of tokenized outputs as PyTorch tensors.\n",
        "'''\n",
        "def bert_tokenize_texts(texts, max_length=128):\n",
        "    return bert_tokenizer(\n",
        "        list(texts),\n",
        "        padding='max_length', # pad shorter texts to max_length\n",
        "        truncation=True, # truncate longer texts\n",
        "        max_length=max_length,\n",
        "        return_tensors='pt' # return PyTorch tensors\n",
        "    )\n",
        "# Tokenize the cleaned sentences from each dataset split for model input\n",
        "bert_train_tokens = bert_tokenize_texts(train_df['cleaned_sentence'].tolist())\n",
        "bert_val_tokens = bert_tokenize_texts(val_df['cleaned_sentence'].tolist())\n",
        "bert_test_tokens = bert_tokenize_texts(test_df['cleaned_sentence'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "kJ_fpYZbtbpw"
      },
      "outputs": [],
      "source": [
        "# create the dataset objects for train, validation and test sets\n",
        "bert_train_dataset = TweetDataset(bert_train_tokens, train_labels)\n",
        "bert_val_dataset = TweetDataset(bert_val_tokens, val_labels)\n",
        "bert_test_dataset = TweetDataset(bert_test_tokens, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dr6seZZDtni-",
        "outputId": "691ecff9-fc6c-471d-f57d-dbac31ab39f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# define the BERT model\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "bert_model = AutoModelForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "fYbrga10t6kk",
        "outputId": "e7a73471-ca00-4d0a-d427-6266c0dbe3fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2433577317.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='945' max='945' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [945/945 02:08, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.320600</td>\n",
              "      <td>1.138213</td>\n",
              "      <td>0.596437</td>\n",
              "      <td>0.512707</td>\n",
              "      <td>0.542236</td>\n",
              "      <td>0.596437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.971000</td>\n",
              "      <td>0.942054</td>\n",
              "      <td>0.687064</td>\n",
              "      <td>0.667162</td>\n",
              "      <td>0.682240</td>\n",
              "      <td>0.687064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.643100</td>\n",
              "      <td>0.892908</td>\n",
              "      <td>0.706429</td>\n",
              "      <td>0.701238</td>\n",
              "      <td>0.700917</td>\n",
              "      <td>0.706429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.469200</td>\n",
              "      <td>0.890552</td>\n",
              "      <td>0.718048</td>\n",
              "      <td>0.722392</td>\n",
              "      <td>0.732509</td>\n",
              "      <td>0.718048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.332200</td>\n",
              "      <td>0.910906</td>\n",
              "      <td>0.723470</td>\n",
              "      <td>0.727008</td>\n",
              "      <td>0.732072</td>\n",
              "      <td>0.723470</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=945, training_loss=0.7596374249332165, metrics={'train_runtime': 128.4466, 'train_samples_per_second': 117.208, 'train_steps_per_second': 7.357, 'total_flos': 990328691424000.0, 'train_loss': 0.7596374249332165, 'epoch': 5.0})"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# setup the trainer and instantiate the train process\n",
        "# initialize the Hugging Face trainer with model, datasets, tokenizer, and evaluation metrics\n",
        "trainer = Trainer(\n",
        "    model=bert_model,\n",
        "    args=training_args,\n",
        "    train_dataset=bert_train_dataset,\n",
        "    eval_dataset=bert_val_dataset,\n",
        "    tokenizer=bert_tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# initialize the training process\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpJfq3XVy3QR",
        "outputId": "8bdb658c-44b0-4454-ca25-e1b7967e5b28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('bert_model/tokenizer_config.json',\n",
              " 'bert_model/special_tokens_map.json',\n",
              " 'bert_model/vocab.txt',\n",
              " 'bert_model/added_tokens.json',\n",
              " 'bert_model/tokenizer.json')"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the fine-tuned model and tokenizer to the specified directory\n",
        "# This allows loading the trained model/tokenizer later for inference or further training\n",
        "bert_model.save_pretrained('bert_model/')\n",
        "bert_tokenizer.save_pretrained('bert_model/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "ED-nHGyMzA1v",
        "outputId": "a9f6bc5b-d481-40bb-ea30-35e63f6cc531"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [116/116 00:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.9302851557731628, 'eval_accuracy': 0.7131236442516269, 'eval_f1': 0.7185259273475617, 'eval_precision': 0.7266192824938815, 'eval_recall': 0.7131236442516269, 'eval_runtime': 3.3717, 'eval_samples_per_second': 546.909, 'eval_steps_per_second': 34.404, 'epoch': 5.0}\n"
          ]
        }
      ],
      "source": [
        "# evaluate on the test dataset\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "predictions = trainer.evaluate(bert_test_dataset)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f41dc48"
      },
      "source": [
        "## Load Saved Models and Predict on Sample Tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49eba197",
        "outputId": "28060367-7e32-40ca-e705-e0802bfb11d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Models and tokenizers loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Define the paths to the saved models and tokenizers\n",
        "xlm_roberta_model_path = 'model/'\n",
        "bert_model_path = 'bert_model/'\n",
        "\n",
        "# Load the XLM-RoBERTa model and tokenizer\n",
        "loaded_xlm_roberta_tokenizer = AutoTokenizer.from_pretrained(xlm_roberta_model_path)\n",
        "loaded_xlm_roberta_model = AutoModelForSequenceClassification.from_pretrained(xlm_roberta_model_path)\n",
        "\n",
        "# Load the mBERT model and tokenizer\n",
        "loaded_bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_path)\n",
        "loaded_bert_model = AutoModelForSequenceClassification.from_pretrained(bert_model_path)\n",
        "\n",
        "print(\"Models and tokenizers loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa63148a",
        "outputId": "03f527bf-05ae-433b-f228-02e3dec14bc6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XLM-RoBERta Predictions:\n",
            "Tweet: 'This is a great service!' -> Prediction: Neutral\n",
            "Tweet: 'I have a problem with my data bundle.' -> Prediction: Internet or airtime bundle complaint\n",
            "Tweet: 'Safaricom Your network is very slow today.' -> Prediction: Network reliability problem\n",
            "Tweet: 'Thank you for your help, your service has been amazing Safaricom.' -> Prediction: Neutral\n",
            "\n",
            "---\n",
            "\n",
            "mBERT Predictions:\n",
            "Tweet: 'This is a great service!' -> Prediction: Neutral\n",
            "Tweet: 'I have a problem with my data bundle.' -> Prediction: Internet or airtime bundle complaint\n",
            "Tweet: 'Safaricom Your network is very slow today.' -> Prediction: Network reliability problem\n",
            "Tweet: 'Thank you for your help, your service has been amazing Safaricom.' -> Prediction: Neutral\n"
          ]
        }
      ],
      "source": [
        "# Define sample tweets\n",
        "sample_tweets = [\n",
        "    \"This is a great service!\",\n",
        "    \"I have a problem with my data bundle.\",\n",
        "    \"Safaricom Your network is very slow today.\",\n",
        "    \"Thank you for your help, your service has been amazing Safaricom.\"\n",
        "]\n",
        "\n",
        "# Define the mapping from encoded labels back to original labels\n",
        "label_map = {\n",
        "    0: \"Customer care complaint\",\n",
        "    1: \"Data protection and privacy concern\",\n",
        "    2: \"Hate Speech\",\n",
        "    3: \"Internet or airtime bundle complaint\",\n",
        "    4: \"MPESA complaint\",\n",
        "    5: \"Network reliability problem\",\n",
        "    6: \"Neutral\"\n",
        "}\n",
        "\n",
        "# Function to get predictions for a list of tweets\n",
        "def get_predictions(tweets, model, tokenizer, label_map):\n",
        "    # Tokenize the sample tweets\n",
        "    inputs = tokenizer(tweets, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    # Move inputs to the same device as the model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "\n",
        "    # Get model predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Get predicted class indices\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "    # Convert predicted indices back to labels\n",
        "    predicted_labels = [label_map[prediction.item()] for prediction in predictions]\n",
        "\n",
        "    return predicted_labels\n",
        "\n",
        "# Get predictions using the loaded XLM-RoBERTa model\n",
        "xlm_roberta_predictions = get_predictions(sample_tweets, loaded_xlm_roberta_model, loaded_xlm_roberta_tokenizer, label_map)\n",
        "print(\"XLM-RoBERta Predictions:\")\n",
        "for tweet, prediction in zip(sample_tweets, xlm_roberta_predictions):\n",
        "    print(f\"Tweet: '{tweet}' -> Prediction: {prediction}\")\n",
        "\n",
        "print(\"\\n---\\n\")\n",
        "\n",
        "# Get predictions using the loaded mBERT model\n",
        "bert_predictions = get_predictions(sample_tweets, loaded_bert_model, loaded_bert_tokenizer, label_map)\n",
        "print(\"mBERT Predictions:\")\n",
        "for tweet, prediction in zip(sample_tweets, bert_predictions):\n",
        "    print(f\"Tweet: '{tweet}' -> Prediction: {prediction}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXijpR3p0fxC",
        "outputId": "ea7519f9-255c-449d-8aae-27f99625481d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/model/ (stored 0%)\n",
            "  adding: content/model/model.safetensors (deflated 21%)\n",
            "  adding: content/model/sentencepiece.bpe.model (deflated 49%)\n",
            "  adding: content/model/special_tokens_map.json (deflated 52%)\n",
            "  adding: content/model/tokenizer.json (deflated 76%)\n",
            "  adding: content/model/config.json (deflated 55%)\n",
            "  adding: content/model/tokenizer_config.json (deflated 76%)\n",
            "  adding: content/bert_model/ (stored 0%)\n",
            "  adding: content/bert_model/model.safetensors (deflated 7%)\n",
            "  adding: content/bert_model/special_tokens_map.json (deflated 42%)\n",
            "  adding: content/bert_model/vocab.txt (deflated 45%)\n",
            "  adding: content/bert_model/tokenizer.json (deflated 67%)\n",
            "  adding: content/bert_model/config.json (deflated 58%)\n",
            "  adding: content/bert_model/tokenizer_config.json (deflated 75%)\n"
          ]
        }
      ],
      "source": [
        "# zip the two models for download\n",
        "!zip -r /content/model.zip /content/model/\n",
        "!zip -r /content/bert_model.zip /content/bert_model/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
