{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20258971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "392d87ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning.ipynb\n",
      "README.md\n",
      "notebook.ipynb\n",
      "saf_tweets_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "#checking files present\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63e18e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Content</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Quotes</th>\n",
       "      <th>Views</th>\n",
       "      <th>Date</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.950000e+18</td>\n",
       "      <td>https://x.com/MawiaDorothy/status/194955836816...</td>\n",
       "      <td>How comes I have overdue debts.. na sijakopa.....</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>July 27, 2025 at 07:51 PM</td>\n",
       "      <td>Customer care complaint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.950000e+18</td>\n",
       "      <td>https://x.com/KruiGeofrey/status/1949310365839...</td>\n",
       "      <td>@Monty_Hasashi @Safaricom ðŸ˜‚ðŸ˜‚</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>July 27, 2025 at 03:26 AM</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.950000e+18</td>\n",
       "      <td>https://x.com/martozgicha/status/1949022872242...</td>\n",
       "      <td>@safaricom weka data ,wacheni jokes...Thank yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>July 26, 2025 at 08:23 AM</td>\n",
       "      <td>Internet or airtime bundle complaint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.950000e+18</td>\n",
       "      <td>https://x.com/liyansmutembei/status/1948476756...</td>\n",
       "      <td>@SafaricomPLC Hello @SafaricomPLC   @safaricom...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>July 24, 2025 at 08:13 PM</td>\n",
       "      <td>Customer care complaint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.950000e+18</td>\n",
       "      <td>https://x.com/SsirNixoNdugire/status/194833516...</td>\n",
       "      <td>@PeterNdegwa_ @SafaricomPLC @Safaricom_Care @S...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>July 24, 2025 at 10:51 AM</td>\n",
       "      <td>Customer care complaint</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tweet ID                                                URL  \\\n",
       "0  1.950000e+18  https://x.com/MawiaDorothy/status/194955836816...   \n",
       "1  1.950000e+18  https://x.com/KruiGeofrey/status/1949310365839...   \n",
       "2  1.950000e+18  https://x.com/martozgicha/status/1949022872242...   \n",
       "3  1.950000e+18  https://x.com/liyansmutembei/status/1948476756...   \n",
       "4  1.950000e+18  https://x.com/SsirNixoNdugire/status/194833516...   \n",
       "\n",
       "                                             Content  Likes  Retweets  \\\n",
       "0  How comes I have overdue debts.. na sijakopa.....      1         0   \n",
       "1                       @Monty_Hasashi @Safaricom ðŸ˜‚ðŸ˜‚      0         0   \n",
       "2  @safaricom weka data ,wacheni jokes...Thank yo...      0         0   \n",
       "3  @SafaricomPLC Hello @SafaricomPLC   @safaricom...      0         0   \n",
       "4  @PeterNdegwa_ @SafaricomPLC @Safaricom_Care @S...      0         0   \n",
       "\n",
       "   Replies  Quotes  Views                       Date  \\\n",
       "0        0       0     21  July 27, 2025 at 07:51 PM   \n",
       "1        0       0     22  July 27, 2025 at 03:26 AM   \n",
       "2        0       0      6  July 26, 2025 at 08:23 AM   \n",
       "3        0       0     47  July 24, 2025 at 08:13 PM   \n",
       "4        0       0      5  July 24, 2025 at 10:51 AM   \n",
       "\n",
       "                                 Labels  \n",
       "0               Customer care complaint  \n",
       "1                               Neutral  \n",
       "2  Internet or airtime bundle complaint  \n",
       "3               Customer care complaint  \n",
       "4               Customer care complaint  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the Safaricom tweets dataset\n",
    "Saf_tweets=pd.read_csv('Safaricom tweets.csv')\n",
    "#Displaying the first few rows of the dataset\n",
    "Saf_tweets.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb6e07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2574 entries, 0 to 2573\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Tweet ID  2574 non-null   float64\n",
      " 1   URL       2574 non-null   object \n",
      " 2   Content   2574 non-null   object \n",
      " 3   Likes     2574 non-null   int64  \n",
      " 4   Retweets  2574 non-null   int64  \n",
      " 5   Replies   2574 non-null   int64  \n",
      " 6   Quotes    2574 non-null   int64  \n",
      " 7   Views     2574 non-null   int64  \n",
      " 8   Date      2574 non-null   object \n",
      " 9   Labels    2573 non-null   object \n",
      "dtypes: float64(1), int64(5), object(4)\n",
      "memory usage: 201.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#checking info\n",
    "Saf_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57463147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral                                 1032\n",
       "Customer care complaint                  397\n",
       "Internet or airtime bundle complaint     299\n",
       "Hate Speech                              297\n",
       "MPESA complaint                          189\n",
       "Network reliability problem              184\n",
       "Data protection and privacy concern      175\n",
       "Name: Labels, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check unique counts in labels\n",
    "Saf_tweets['Labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64792f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for duplicated values\n",
    "Saf_tweets.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f8be69",
   "metadata": {},
   "source": [
    "### Data cleaning and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82244d62",
   "metadata": {},
   "source": [
    "##### Contradiction dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1350802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Contractions dictionary\n",
    "contractions = {\n",
    "    \"won't\": \"will not\", \"can't\": \"cannot\", \"n't\": \" not\",\n",
    "    \"'re\": \" are\", \"'ve\": \" have\", \"'ll\": \" will\",\n",
    "    \"'d\": \" would\", \"'m\": \" am\", \"it's\": \"it is\",\n",
    "    \"that's\": \"that is\", \"what's\": \"what is\",\n",
    "    \"there's\": \"there is\", \"here's\": \"here is\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b578a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions_text(text, contractions=contractions):\n",
    "    \"\"\"Expand contractions in the text.\"\"\"\n",
    "    for contraction, expansion in contractions.items():\n",
    "        text = text.replace(contraction, expansion)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d81161",
   "metadata": {},
   "source": [
    "#### Removing repeated characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d589d7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repeated_characters(text):\n",
    "    \"\"\"Reduce repeated characters (e.g., soooo â†’ soo).\"\"\"\n",
    "    return re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915262ab",
   "metadata": {},
   "source": [
    "##### Basic cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a81bfab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cleaning(text, \n",
    "                   remove_urls=True,\n",
    "                   remove_mentions=True,\n",
    "                   remove_hashtags=True):\n",
    "    \"\"\"Apply basic regex cleaning to text.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    \n",
    "    text = str(text)\n",
    "\n",
    "    if remove_urls:\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "\n",
    "    if remove_mentions:\n",
    "        text = re.sub(r'@\\w+', '', text)\n",
    "\n",
    "    if remove_hashtags:\n",
    "        text = re.sub(r'#', '', text)\n",
    "\n",
    "    text = re.sub(r'[^a-zA-Z\\s!?]', '', text)  # Remove special chars but keep ! ?\n",
    "    text = re.sub(r'!+', '!', text)\n",
    "    text = re.sub(r'\\?+', '?', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb41e79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_pipeline(text,\n",
    "                        expand_contractions=True,\n",
    "                        remove_repeated_chars=True,\n",
    "                        remove_urls=True,\n",
    "                        remove_mentions=True,\n",
    "                        remove_hashtags=True):\n",
    "    \"\"\"Complete cleaning pipeline (no tokenizing or lemmatizing).\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    \n",
    "    text = str(text)\n",
    "\n",
    "    if expand_contractions:\n",
    "        text = expand_contractions_text(text)\n",
    "    \n",
    "    if remove_repeated_chars:\n",
    "        text = remove_repeated_characters(text)\n",
    "\n",
    "    text = basic_cleaning(\n",
    "        text,\n",
    "        remove_urls=remove_urls,\n",
    "        remove_mentions=remove_mentions,\n",
    "        remove_hashtags=remove_hashtags\n",
    "    )\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0818494c",
   "metadata": {},
   "source": [
    "## Testing if it has worked with some tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47f62a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned: My network is misbehaving\n",
      "Cleaned: rudisheni hii na mnipee bundles sasa sms nazifanyia nini\n",
      "Cleaned: \n",
      "Cleaned: you are a scam\n"
     ]
    }
   ],
   "source": [
    "tweets = [\n",
    "    \"My @safaricom network is misbehaving\",\n",
    "    \"@safaricom rudisheni hii na mnipee bundles .sasa sms nazifanyia nini https://t.co/CvaD1kd5wM\",\n",
    "    \"@Shikanda_00 @safaricom\",\n",
    "    \"@safaricom you are a scam https://t.co/80BRkJ5uB2\"\n",
    "]\n",
    "\n",
    "for t in tweets:\n",
    "    print(\"Cleaned:\", clean_text_pipeline(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "876dfe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing it on the Safaricom tweets dataset\n",
    "Saf_tweets['Cleaned_Text'] = Saf_tweets['Content'].apply(clean_text_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0840c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How comes I have overdue debts.. na sijakopa.....</td>\n",
       "      <td>How comes I have overdue debts na sijakopawhat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Monty_Hasashi @Safaricom ðŸ˜‚ðŸ˜‚</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@safaricom weka data ,wacheni jokes...Thank yo...</td>\n",
       "      <td>weka data wacheni jokesThank you for being par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@SafaricomPLC Hello @SafaricomPLC   @safaricom...</td>\n",
       "      <td>Hello can you borrow from Airtel and allow man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@PeterNdegwa_ @SafaricomPLC @Safaricom_Care @S...</td>\n",
       "      <td>Jambo Kindly consider introducing a Narration ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  How comes I have overdue debts.. na sijakopa.....   \n",
       "1                       @Monty_Hasashi @Safaricom ðŸ˜‚ðŸ˜‚   \n",
       "2  @safaricom weka data ,wacheni jokes...Thank yo...   \n",
       "3  @SafaricomPLC Hello @SafaricomPLC   @safaricom...   \n",
       "4  @PeterNdegwa_ @SafaricomPLC @Safaricom_Care @S...   \n",
       "\n",
       "                                        Cleaned_Text  \n",
       "0  How comes I have overdue debts na sijakopawhat...  \n",
       "1                                                     \n",
       "2  weka data wacheni jokesThank you for being par...  \n",
       "3  Hello can you borrow from Airtel and allow man...  \n",
       "4  Jambo Kindly consider introducing a Narration ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Saf_tweets[['Content', 'Cleaned_Text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5c3049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#savinga the cleaned tweets to a new CSV file\n",
    "Saf_tweets[['Content', 'Cleaned_Text']].to_csv('saf_tweets_cleaned.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "856c6874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning.ipynb\n",
      "README.md\n",
      "Safaricom tweets.csv\n",
      "notebook.ipynb\n",
      "saf_tweets_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
